{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7278be14",
   "metadata": {},
   "source": [
    "# Performance Benchmarking: PID vs RL Controller\n",
    "\n",
    "This notebook benchmarks the PID and RL controllers on the `OT2Env` environment.\n",
    "We evaluate each controller over multiple episodes and compare performance on key metrics:\n",
    "- Reward\n",
    "- Steps\n",
    "- Success Rate\n",
    "\n",
    "We visualize results using **line plots, bar charts, and boxplots**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cafeed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from pid_controller import PIDController\n",
    "from ot2_gym_wrapper_2 import OT2Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a993f088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "EPISODES = 20\n",
    "PID_GAINS = (0.5, 0.01, 0.1)  # Example PID gains\n",
    "RL_MODEL_PATH = \"models/0jfld8sq/final_model.zip\"\n",
    "RESULTS_CSV = \"benchmark_results.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c7dc560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pid(env, pid, episodes=20):\n",
    "    rewards, steps, success = [], [], []\n",
    "    for _ in range(episodes):\n",
    "        obs, _ = env.reset()\n",
    "        pid.set_target(env.goal_position)\n",
    "        done, ep_reward, t = False, 0, 0\n",
    "        while not done:\n",
    "            action = pid.update(env.get_current_position())\n",
    "            obs, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            ep_reward += reward\n",
    "            t += 1\n",
    "        rewards.append(ep_reward)\n",
    "        steps.append(t)\n",
    "        success.append(terminated)\n",
    "    return rewards, steps, success\n",
    "\n",
    "def evaluate_rl(env, model, episodes=20):\n",
    "    rewards, steps, success = [], [], []\n",
    "    for _ in range(episodes):\n",
    "        obs, _ = env.reset()\n",
    "        done, ep_reward, t = False, 0, 0\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            ep_reward += reward\n",
    "            t += 1\n",
    "        rewards.append(ep_reward)\n",
    "        steps.append(t)\n",
    "        success.append(env.success)\n",
    "    return rewards, steps, success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28a23cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'OT2Env' object has no attribute 'success'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# RL Benchmark\u001b[39;00m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO\u001b[38;5;241m.\u001b[39mload(RL_MODEL_PATH, env\u001b[38;5;241m=\u001b[39menv, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m rl_rewards, rl_steps, rl_success \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_rl\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPISODES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Collect results\u001b[39;00m\n\u001b[0;32m     13\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontroller\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m EPISODES \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRL\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m EPISODES,\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m'\u001b[39m: pid_rewards \u001b[38;5;241m+\u001b[39m rl_rewards,\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msteps\u001b[39m\u001b[38;5;124m'\u001b[39m: pid_steps \u001b[38;5;241m+\u001b[39m rl_steps,\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m'\u001b[39m: pid_success \u001b[38;5;241m+\u001b[39m rl_success,\n\u001b[0;32m     18\u001b[0m })\n",
      "Cell \u001b[1;32mIn[11], line 31\u001b[0m, in \u001b[0;36mevaluate_rl\u001b[1;34m(env, model, episodes)\u001b[0m\n\u001b[0;32m     29\u001b[0m     rewards\u001b[38;5;241m.\u001b[39mappend(ep_reward)\n\u001b[0;32m     30\u001b[0m     steps\u001b[38;5;241m.\u001b[39mappend(t)\n\u001b[1;32m---> 31\u001b[0m     success\u001b[38;5;241m.\u001b[39mappend(\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuccess\u001b[49m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rewards, steps, success\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'OT2Env' object has no attribute 'success'"
     ]
    }
   ],
   "source": [
    "# Initialize environment\n",
    "env = OT2Env()\n",
    "\n",
    "# PID Benchmark\n",
    "pid = PIDController(*PID_GAINS)\n",
    "pid_rewards, pid_steps, pid_success = evaluate_pid(env, pid, EPISODES)\n",
    "\n",
    "# RL Benchmark\n",
    "model = PPO.load(RL_MODEL_PATH, env=env, device='cpu')\n",
    "rl_rewards, rl_steps, rl_success = evaluate_rl(env, model, EPISODES)\n",
    "\n",
    "# Collect results\n",
    "df = pd.DataFrame({\n",
    "    'controller': ['PID'] * EPISODES + ['RL'] * EPISODES,\n",
    "    'reward': pid_rewards + rl_rewards,\n",
    "    'steps': pid_steps + rl_steps,\n",
    "    'success': pid_success + rl_success,\n",
    "})\n",
    "df.to_csv(RESULTS_CSV, index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b8a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Line Plots ---\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(EPISODES), pid_rewards, label='PID')\n",
    "plt.plot(range(EPISODES), rl_rewards, label='RL')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.title('Reward per Episode')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(EPISODES), pid_steps, label='PID')\n",
    "plt.plot(range(EPISODES), rl_steps, label='RL')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Steps')\n",
    "plt.title('Steps per Episode')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed3bbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Bar Chart: Success Rate ---\n",
    "success_rate = df.groupby('controller')['success'].mean()\n",
    "success_rate.plot(kind='bar', ylabel='Success Rate', title='Controller Success Rate', rot=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1321ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Boxplots ---\n",
    "df.boxplot(column='reward', by='controller', grid=False)\n",
    "plt.title('Reward Distribution')\n",
    "plt.suptitle('')\n",
    "plt.show()\n",
    "\n",
    "df.boxplot(column='steps', by='controller', grid=False)\n",
    "plt.title('Steps Distribution')\n",
    "plt.suptitle('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb789ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Summary Statistics ---\n",
    "\n",
    "summary = df.groupby('controller').agg(\n",
    "    reward_mean=('reward', 'mean'),\n",
    "    reward_std=('reward', 'std'),\n",
    "    steps_mean=('steps', 'mean'),\n",
    "    steps_std=('steps', 'std'),\n",
    "    success_rate=('success', 'mean')\n",
    ")\n",
    "\n",
    "# Display with rounded values for readability\n",
    "summary.round(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "block_b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
